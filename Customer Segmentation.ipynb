{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation Project\n",
    "\n",
    "Customer segmentation is the problem of uncovering information about a firm’s customer base, based on their interactions with the business.\n",
    "\n",
    "Importants of Customer Segmentation, it can be used for\n",
    "1. Customer Understanding\n",
    "2. Target Marketing\n",
    "3. Optimal Product Placement\n",
    "4. Finding Latent Customer Segments\n",
    "5. Higher Revenue\n",
    "\n",
    "The dataset used is an online retail transactions that is available on the UCI Machine Learning Repository it contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.\n",
    "\n",
    "The dataset is made up of the following columns:\n",
    "* InvoiceNo: A unique identifier for the invoice. An invoice number shared across rows means that those transactions were performed in a single invoice (multiple purchases).\n",
    "*  StockCode: Identifier for items contained in an invoice.\n",
    "* Description: Textual description of each of the stock item.\n",
    "* Quantity: The quantity of the item purchased.\n",
    "* InvoiceDate: Date of purchase.\n",
    "* UnitPrice: Value of each item.\n",
    "* CustomerID: Identifier for customer making the purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Our Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmyvera/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Our Dataset Into Our Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Pandas requires version '3.0.0' or newer of 'openpyxl' (version '2.6.1' currently installed).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3ede8bc50862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'Online Retail.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mfsspec\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mappropriate\u001b[0m \u001b[0mURLs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_get_filepath_or_buffer\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \"\"\"\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"openpyxl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Pandas requires version '3.0.0' or newer of 'openpyxl' (version '2.6.1' currently installed)."
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(io=r'Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "After loading our dataset the first thing we need to do is get familiar with our dataset by performing Exploration Data Analysis (EDA) for short "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let explore the country, which country get shipped the most \n",
    "df.Country.value_counts().reset_index().head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the UK has the most shipped item by the retailer, It not surprising because that is the homecountry of the retail store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now how many unique customers the retailer is having and \n",
    "# how do they stack up in the number of orders they make.\n",
    "\n",
    "print(f'The online store has {df.CustomerID.unique().shape[0]} unique customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.CustomerID.value_counts()/sum(df.CustomerID.value_counts())*100).head(n=13).cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that we have 4,373 unique customers but almost 10% of total sales are contributed by only 13 customers (based on the cumulative percentage aggregation in the preceding output). \n",
    "\n",
    "This is expected given the fact that we have both wholesale and retail customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique items the firm is selling? and \n",
    "# does it have equal number of descriptions for them?.\n",
    "\n",
    "print(f'The store has {df.StockCode.unique().shape[0]} unique item' )\n",
    "print(f'And {df.StockCode.unique().shape[0]} number of descriptions unique item' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can notice the mismatch in the `StockCode` and `Description`. Let us dig a little bit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_des_df = df.groupby([\"StockCode\",\"Description\"]).count().reset_index()\n",
    "cat_des_df.StockCode.value_counts()[cat_des_df.StockCode.value_counts()>1].reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['StockCode']==cat_des_df.StockCode.value_counts()[cat_des_df.StockCode.value_counts()>1].reset_index()['index'][6]]['Description'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that multiple descriptions for one of those items and we witness the simple ways in which data quality can be corrupted in any dataset. A simple spelling mistake can end up in reducing data quality and an erroneous analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Quantity', 'UnitPrice']].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the preceding output that both of these attributes are having negative values, which may mean that we may have some return transactions in our data also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "\n",
    "#### RFM Model for Customer Value\n",
    "\n",
    "The RFM model is a popular model in marketing and customer segmentation for determining a customer’s value. The RFM model will take the transactions of a customer and calculate three important informational attributes about each customer:\n",
    "\n",
    "* Recency: The value of how recently a customer purchased at the establishment\n",
    "\n",
    "* Frequency: How frequent the customer’s transactions are at the establishment\n",
    "\n",
    "* Monetary value: The dollar (or pounds in our case) value of all the transactions that the customer made at the establishment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our “Exploratory Data Analysis” section we noticed that some goods were return, we saw it in our dataset. Before proceeding with our analysis workflow, we will find out all such transactions and remove them. Another possibility is to remove the matching buying transactions also from the dataset. But we will assume that those transactions are still important hence we will keep them intact. Another data cleaning operation is to separate transactions for a particular geographical region only, as we don’t want data from Germany’s customers to affect the analysis for another country’s customers. The following snippet of code achieves both these tasks. We focus on UK customers, which are notably the largest segment (based on country!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data for one geography (UK)\n",
    "df = df[df.Country == 'United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate attribute for total amount\n",
    "df['amount'] = df.Quantity*df.UnitPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove negative or return transactions\n",
    "df = df[~(df.amount<0)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset now has only buying transactions from United Kingdom. We will now remove all the transactions that have a missing value for the CustomerID field as all our subsequent transactions will be based on the customer entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the Customer that has CustomerID \n",
    "df = df[~(df.CustomerID.isnull())]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recency\n",
    "\n",
    "To create the recency feature variable, we need to decide the reference date for our analysis. For our use case, we will define the reference date as one day after the last transaction in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refrence_date = df.InvoiceDate.max()\n",
    "refrence_date = refrence_date + datetime.timedelta(days = 1)\n",
    "refrence_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_since_last_purchase'] = refrence_date - df.InvoiceDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_since_last_purchase_num'] = df['days_since_last_purchase'].astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_history_df = df.groupby(\"CustomerID\").min().reset_index()[['CustomerID', 'days_since_last_purchase_num']]\n",
    "\n",
    "customer_history_df.rename(columns={'days_since_last_purchase_num':'recency'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the histogram of sales recency\n",
    "\n",
    "x = customer_history_df.recency\n",
    "mu = np.mean(customer_history_df.recency)\n",
    "sigma = math.sqrt(np.var(customer_history_df.recency))\n",
    "n, bins, patches = plt.hist(x, 1000, facecolor='green', alpha=0.75)\n",
    "\n",
    "# add a 'best fit' line\n",
    "plt.xlabel('Recency in days')\n",
    "plt.ylabel('Number of transactions')\n",
    "plt.title(r'$\\mathrm{Histogram\\ of\\ sales\\ recency}\\ $')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this histogram tells us that we have skewed distribution of sales recency with a much higher number of frequent transactions and a fairly uniform number of less recent transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency and Monetary Value\n",
    "\n",
    "Using similar methods, we can create a frequency and monetary value variable for our dataset. We will create these variables separately and then merge all the dataframes to arrive at the customer value dataset.\n",
    "\n",
    "We will also perform our clustering-based customer segmentation on this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_monetary_val = df[['CustomerID', 'amount']].groupby(\"CustomerID\").sum().reset_index()\n",
    "customer_history_df = customer_history_df.merge(customer_monetary_val, how='outer')\n",
    "customer_history_df.amount = customer_history_df.amount+0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_freq = df[['CustomerID', 'amount']].groupby(\"CustomerID\").count().reset_index()\n",
    "customer_freq.rename(columns={'amount':'frequency'},inplace=True)\n",
    "customer_history_df = customer_history_df.merge(customer_freq, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_history_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Why do we scale our data (#StandardScaler #MeanCentering)\n",
    "Mean centering of a variable value means that we will replace the actual value of the variable with a standardized value, so that the variable has a mean of 1 and variance of 0. This ensures that all the variables are in the same range and the difference in ranges of values doesn’t cause the algorithm to not perform well.\n",
    "This is akin to feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import math\n",
    "customer_history_df['recency_log'] = customer_history_df['recency'].apply(math.log)\n",
    "customer_history_df['frequency_log'] = customer_history_df['frequency'].apply(math.log)\n",
    "customer_history_df['amount_log'] = customer_history_df['amount'].apply(math.log)\n",
    "feature_vector = ['amount_log', 'recency_log','frequency_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = customer_history_df[feature_vector].as_matrix()\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To visualise the results of our preprocessing \n",
    "## by inspecting the variable with the widest range of values\n",
    "\n",
    "x = customer_history_df.amount_log\n",
    "n, bins, patches = plt.hist(x, 1000, facecolor='green', alpha=0.75)\n",
    "plt.xlabel('Log of Sales Amount')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(r'$\\mathrm{Histogram\\ of\\ Log\\ transformed\\ Customer\\ Monetary\\ value}\\ $')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We visualize our three main features (R, F, and M) on a three-dimensional plot \n",
    "## to see if we can understand any interesting patterns that the data \n",
    "## distribution is showing.\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "xs =customer_history_df.recency_log\n",
    "ys = customer_history_df.frequency_log\n",
    "zs = customer_history_df.amount_log\n",
    "ax.scatter(xs, ys, zs, s=5)\n",
    "ax.set_xlabel('Recency')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Monetary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious patterns we can see from the plot is that people who buy with a higher frequency and more recency tend to spend more based on the increasing trend in Monetary value with a corresponding increasing and decreasing trend for Frequency and Recency, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "## K-Means Clustering\n",
    "\n",
    "The K-means clustering belongs to the partition based\\centroid based clustering family of algorithms. The steps that happen in the K-means algorithm for partitioning the data are as given follows:\n",
    "\n",
    "1. The algorithm starts with random point initializations of the required number of centers. The “K” in K-means stands for the number of clusters.\n",
    "\n",
    "2. In the next step, each of the data point is assigned to the center closest to it. The distance metric used in K-means clustering is normal Euclidian distance.\n",
    "\n",
    "3. Once the data points are assigned, the centers are recalculated by averaging the dimensions of the points belonging to the cluster.\n",
    "\n",
    "4. The process is repeated with new centers until we reach a point where the assignments become stable. In this case, the algorithm terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "X = X_scaled\n",
    "\n",
    "cluster_centers = dict()\n",
    "\n",
    "for n_clusters in range(3,6,2):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    #ax2 = plt.subplot(111, projection='3d')\n",
    "    fig.set_size_inches(18, 7)\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    cluster_centers.update({n_clusters :{\n",
    "                                        'cluster_center':clusterer.cluster_centers_,\n",
    "                                        'silhouette_score':silhouette_avg,\n",
    "                                        'labels':cluster_labels}\n",
    "                           })\n",
    "\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.Spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    colors = cm.Spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    feature1 = 0\n",
    "    feature2 = 2\n",
    "    ax2.scatter(X[:, feature1], X[:, feature2], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "    \n",
    "    centers = clusterer.cluster_centers_\n",
    "    ax2.scatter(centers[:, feature1], centers[:, feature2], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[feature1], c[feature2], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature i.e. monetary value\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature i.e. frequency\")\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the visualization depicted, we plotted the silhouette score of each cluster along with the center of each of the cluster discovered. \n",
    "\n",
    "Although we have to keep in mind that in several cases and scenarios, sometimes we may have to drop the mathematical explanation given by the algorithm and look at the business relevance of the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,6,2):\n",
    "    print(\"for {} number of clusters\".format(i))\n",
    "    cent_transformed = scaler.inverse_transform(cluster_centers[i]['cluster_center'])\n",
    "    print(pd.DataFrame(np.exp(cent_transformed),columns=feature_vector))\n",
    "    print(\"Silhouette score for cluster {} is {}\". format(i, cluster_centers[i]['silhouette_score']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results of the clustering process, we can infer some interesting insights. \n",
    "\n",
    "Consider the three-cluster configuration we understand the following insights.\n",
    "1. We get three clusters with stark differences in the Monetary value of the customer.\n",
    "2. Cluster 2 is the cluster of high value customer who shops frequently and is certainly an important segment for each business.\n",
    "3. In the similar way we obtain customer groups with low and medium spends in clusters with labels 1 and 0, respectively.\n",
    "4. Frequency and Recency correlate perfectly to the Monetary value based on the trendwe talked about in Figure 8-3 (High Monetary-Low Recency-High Frequency).\n",
    "\n",
    "\n",
    "The five-cluster configuration results are more surprising! When we go looking for more segments, we find out that our high valued customer base is comprised of two subgroups:\n",
    "\n",
    "1. Those who shop often and with high amount (represented by cluster 0).\n",
    "2. Those who have a decent spend but are not as frequent (represented by cluster 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Descriptions\n",
    "\n",
    "On the basis of eyeballing the cluster centers, we can figure out that we have a good difference in the customer value in the segments as defined in terms of recency, amount and frequency. \n",
    "\n",
    "To further drill down on this point and find out the quality of these difference, we can label our data with the corresponding cluster label and then visualize these differences. We will do this visualization for probably one of the most important customer value indicators, the total dollar value sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = cluster_centers[5]['labels']\n",
    "customer_history_df['num_cluster5_labels'] = labels\n",
    "labels = cluster_centers[3]['labels']\n",
    "customer_history_df['num_cluster3_labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.offline.init_notebook_mode()\n",
    "\n",
    "x_data = ['Cluster 1','Cluster 2','Cluster 3','Cluster 4', 'Cluster 5']\n",
    "cutoff_quantile = 80\n",
    "field_to_plot = 'amount'\n",
    "\n",
    "y0=customer_history_df[customer_history_df['num_cluster5_labels']==0][field_to_plot].values\n",
    "y0 = y0[y0<np.percentile(y0, cutoff_quantile)]\n",
    "\n",
    "y1 = customer_history_df[customer_history_df['num_cluster5_labels']==1][field_to_plot].values\n",
    "y1 = y1[y1<np.percentile(y1, cutoff_quantile)]\n",
    "\n",
    "y2=customer_history_df[customer_history_df['num_cluster5_labels']==2][field_to_plot].values\n",
    "y2 = y2[y2<np.percentile(y2, cutoff_quantile)]\n",
    "\n",
    "y3=customer_history_df[customer_history_df['num_cluster5_labels']==3][field_to_plot].values\n",
    "y3 = y3[y3<np.percentile(y3, cutoff_quantile)]\n",
    "\n",
    "y4=customer_history_df[customer_history_df['num_cluster5_labels']==4][field_to_plot].values\n",
    "y4 = y4[y4<np.percentile(y4, cutoff_quantile)]\n",
    "\n",
    "y_data = [y0,y1,y2,y3,y4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)', 'rgba(44, 160, 101, 0.5)',\n",
    "'rgba(255, 65, 54, 0.5)', 'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)']\n",
    "traces = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xd, yd, cls in zip(x_data, y_data, colors):\n",
    "    traces.append(go.Box(\n",
    "        y=yd, \n",
    "        name=xd, \n",
    "        boxpoints=False, \n",
    "        jitter=0.5,\n",
    "        whiskerwidth=0.2,\n",
    "        fillcolor=cls,\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "        ), \n",
    "        line=dict(width=1), \n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = go.Layout(\n",
    "    title='Difference in sales {} from cluster to cluster'.format(field_to_plot),\n",
    "    yaxis=dict(\n",
    "        autorange=True,\n",
    "        showgrid=True,\n",
    "        zeroline=True,\n",
    "        dtick=1000,\n",
    "        gridcolor='black',\n",
    "        gridwidth=0.1,\n",
    "        zerolinecolor='rgb(255, 255, 255)',\n",
    "        zerolinewidth=2,\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=40,\n",
    "        r=30, \n",
    "        b=80, \n",
    "        t=100,\n",
    "    ),\n",
    "    paper_bgcolor='white',\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=traces, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Clusters 2 and 3 have a higher average sales amount, thus being the highest spenders. Although we don’t see much difference in the sales values of Clusters 1, 4 and 5, we do see a markedly smaller sales amount\n",
    "in Cluster 1. \n",
    "\n",
    "This gives us an indication that we can merge the candidates of Clusters 4 and 5 together, at\n",
    "least on the basis of sales amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = ['Cluster 1','Cluster 2','Cluster 3','Cluster 4', 'Cluster 5']\n",
    "cutoff_quantile = 100\n",
    "field_to_plot = 'recency'\n",
    "\n",
    "y0 = customer_history_df[customer_history_df['num_cluster5_labels']==0][field_to_plot].values\n",
    "y0 = y0[y0<np.percentile(y0, cutoff_quantile)]\n",
    "y1 = customer_history_df[customer_history_df['num_cluster5_labels']==1][field_to_plot].values\n",
    "y1 = y1[y1<np.percentile(y1, cutoff_quantile)]\n",
    "y2 = customer_history_df[customer_history_df['num_cluster5_labels']==2][field_to_plot].values\n",
    "y2 = y2[y2<np.percentile(y2, cutoff_quantile)]\n",
    "y3 = customer_history_df[customer_history_df['num_cluster5_labels']==3][field_to_plot].values\n",
    "y3 = y3[y3<np.percentile(y3, cutoff_quantile)]\n",
    "y4 = customer_history_df[customer_history_df['num_cluster5_labels']==4][field_to_plot].values\n",
    "y4 = y4[y4<np.percentile(y4, cutoff_quantile)]\n",
    "y_data = [y0,y1,y2,y3,y4]\n",
    "\n",
    "colors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)', 'rgba(44, 160, 101, 0.5)', 'rgba(255, 65, 54, 0.5)', 'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)']\n",
    "traces = []\n",
    "\n",
    "for xd, yd, cls in zip(x_data, y_data, colors):\n",
    "        traces.append(go.Box(\n",
    "            y=yd,\n",
    "            name=xd,\n",
    "            boxpoints=False,\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            fillcolor=cls,\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "            ),\n",
    "            line=dict(width=1),\n",
    "        ))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Difference in sales {} from cluster to cluster'.format(field_to_plot),\n",
    "    yaxis=dict(\n",
    "        autorange=True,\n",
    "        showgrid=True,\n",
    "        zeroline=True,\n",
    "        dtick=50,\n",
    "        gridcolor='black',\n",
    "        gridwidth=0.1,\n",
    "        zerolinecolor='rgb(255, 255, 255)',\n",
    "        zerolinewidth=2,\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=40,\n",
    "        r=30,\n",
    "        b=80,\n",
    "        t=100,\n",
    "    ),\n",
    "    paper_bgcolor='white',\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow We can see that the Clusters 2 and 4 visit the online store recently. We also see much difference in the sales recency of Clusters 1 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = ['Cluster 1','Cluster 2','Cluster 3','Cluster 4', 'Cluster 5']\n",
    "cutoff_quantile = 80\n",
    "field_to_plot = 'frequency'\n",
    "y0 = customer_history_df[customer_history_df['num_cluster5_labels']==0][field_to_plot].values\n",
    "y0 = y0[y0<np.percentile(y0, cutoff_quantile)]\n",
    "y1 = customer_history_df[customer_history_df['num_cluster5_labels']==1][field_to_plot].values\n",
    "y1 = y1[y1<np.percentile(y1, cutoff_quantile)]\n",
    "y2 = customer_history_df[customer_history_df['num_cluster5_labels']==2][field_to_plot].values\n",
    "y2 = y2[y2<np.percentile(y2, cutoff_quantile)]\n",
    "y3 = customer_history_df[customer_history_df['num_cluster5_labels']==3][field_to_plot].values\n",
    "y3 = y3[y3<np.percentile(y3, cutoff_quantile)]\n",
    "y4 = customer_history_df[customer_history_df['num_cluster5_labels']==4][field_to_plot].values\n",
    "y4 = y4[y4<np.percentile(y4, cutoff_quantile)]\n",
    "y_data = [y0,y1,y2,y3,y4]\n",
    "\n",
    "colors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)', 'rgba(44, 160, 101, 0.5)', 'rgba(255, 65, 54, 0.5)', 'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)']\n",
    "traces = []\n",
    "\n",
    "for xd, yd, cls in zip(x_data, y_data, colors):\n",
    "        traces.append(go.Box(\n",
    "            y=yd,\n",
    "            name=xd,\n",
    "            boxpoints=False,\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            fillcolor=cls,\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "            ),\n",
    "            line=dict(width=1),\n",
    "        ))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Difference in sales {} from cluster to cluster'.format(field_to_plot),\n",
    "    yaxis=dict(\n",
    "        autorange=True,\n",
    "        showgrid=True,\n",
    "        zeroline=True,\n",
    "        dtick=100,\n",
    "        gridcolor='black',\n",
    "        gridwidth=0.1,\n",
    "        zerolinecolor='rgb(255, 255, 255)',\n",
    "        zerolinewidth=2,\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=40,\n",
    "        r=30,\n",
    "        b=80,\n",
    "        t=100,\n",
    "    ),\n",
    "    paper_bgcolor='white',\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = ['Cluster 1','Cluster 2','Cluster 3']\n",
    "cutoff_quantile = 100\n",
    "field_to_plot = 'recency'\n",
    "y0 = customer_history_df[customer_history_df['num_cluster3_labels']==0][field_to_plot].values\n",
    "y0 = y0[y0<np.percentile(y0, cutoff_quantile)]\n",
    "y1 = customer_history_df[customer_history_df['num_cluster3_labels']==1][field_to_plot].values\n",
    "y1 = y1[y1<np.percentile(y1, cutoff_quantile)]\n",
    "y2 = customer_history_df[customer_history_df['num_cluster3_labels']==2][field_to_plot].values\n",
    "y2 = y2[y2<np.percentile(y2, cutoff_quantile)]\n",
    "\n",
    "y_data = [y0,y1,y2]\n",
    "\n",
    "colors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)', 'rgba(44, 160, 101, 0.5)', 'rgba(255, 65, 54, 0.5)', 'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)']\n",
    "traces = []\n",
    "\n",
    "for xd, yd, cls in zip(x_data, y_data, colors):\n",
    "        traces.append(go.Box(\n",
    "            y=yd,\n",
    "            name=xd,\n",
    "            boxpoints=False,\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            fillcolor=cls,\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "            ),\n",
    "            line=dict(width=1),\n",
    "        ))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Difference in sales {} from cluster to cluster'.format(field_to_plot),\n",
    "    yaxis=dict(\n",
    "        autorange=True,\n",
    "        showgrid=True,\n",
    "        zeroline=True,\n",
    "        dtick=50,\n",
    "        gridcolor='black',\n",
    "        gridwidth=0.1,\n",
    "        zerolinecolor='rgb(255, 255, 255)',\n",
    "        zerolinewidth=2,\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=40,\n",
    "        r=30,\n",
    "        b=80,\n",
    "        t=100,\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = ['Cluster 1','Cluster 2','Cluster 3']\n",
    "cutoff_quantile = 80\n",
    "field_to_plot = 'amount'\n",
    "y0 = customer_history_df[customer_history_df['num_cluster3_labels']==0][field_to_plot].values\n",
    "y0 = y0[y0<np.percentile(y0, cutoff_quantile)]\n",
    "y1 = customer_history_df[customer_history_df['num_cluster3_labels']==1][field_to_plot].values\n",
    "y1 = y1[y1<np.percentile(y1, cutoff_quantile)]\n",
    "y2 = customer_history_df[customer_history_df['num_cluster3_labels']==2][field_to_plot].values\n",
    "y2 = y2[y2<np.percentile(y2, cutoff_quantile)]\n",
    "\n",
    "y_data = [y0,y1,y2]\n",
    "\n",
    "colors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)', 'rgba(44, 160, 101, 0.5)', 'rgba(255, 65, 54, 0.5)', 'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)']\n",
    "traces = []\n",
    "\n",
    "for xd, yd, cls in zip(x_data, y_data, colors):\n",
    "        traces.append(go.Box(\n",
    "            y=yd,\n",
    "            name=xd,\n",
    "            boxpoints=False,\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            fillcolor=cls,\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "            ),\n",
    "            line=dict(width=1),\n",
    "        ))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Difference in sales {} from cluster to cluster'.format(field_to_plot),\n",
    "    yaxis=dict(        \n",
    "        dtick=1000,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Clusters 3 has the highest average sales amount, thus being the highest spenders, 2 have a higher average sales amount greater than Cluster 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = ['Cluster 1','Cluster 2','Cluster 3']\n",
    "cutoff_quantile = 90\n",
    "field_to_plot = 'frequency'\n",
    "y0 = customer_history_df[customer_history_df['num_cluster3_labels']==0][field_to_plot].values\n",
    "y0 = y0[y0<np.percentile(y0, cutoff_quantile)]\n",
    "y1 = customer_history_df[customer_history_df['num_cluster3_labels']==1][field_to_plot].values\n",
    "y1 = y1[y1<np.percentile(y1, cutoff_quantile)]\n",
    "y2 = customer_history_df[customer_history_df['num_cluster3_labels']==2][field_to_plot].values\n",
    "y2 = y2[y2<np.percentile(y2, cutoff_quantile)]\n",
    "\n",
    "y_data = [y0,y1,y2]\n",
    "\n",
    "colors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)', 'rgba(44, 160, 101, 0.5)', 'rgba(255, 65, 54, 0.5)', 'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)']\n",
    "traces = []\n",
    "\n",
    "for xd, yd, cls in zip(x_data, y_data, colors):\n",
    "        traces.append(go.Box(\n",
    "            y=yd,\n",
    "            name=xd,\n",
    "            boxpoints=False,\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            fillcolor=cls,\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "            ),\n",
    "            line=dict(width=1),\n",
    "        ))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Difference in sales {} from cluster to cluster'.format(field_to_plot),\n",
    "    yaxis=dict(\n",
    "        autorange=True,\n",
    "        showgrid=True,\n",
    "        zeroline=True,\n",
    "        dtick=100,\n",
    "        gridcolor='black',\n",
    "        gridwidth=0.1,\n",
    "        zerolinecolor='rgb(255, 255, 255)',\n",
    "        zerolinewidth=2,\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=40,\n",
    "        r=30,\n",
    "        b=80,\n",
    "        t=100,\n",
    "    ),\n",
    "    paper_bgcolor='white',\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Summary\n",
    "\n",
    "The important caveat from this analysis is that when it comes to correlating the actual value of results with the mathematical metrics we cannot always rely on the metrics. We need to include this habit of\n",
    "including business metrics and domain insights in our modeling process as often times this becomes the difference between an implemented high value project and a forgotten data-focused solution. \n",
    "\n",
    "Once we obtain these results, we can further discuss them with the marketing team of the organization to come up with appropriate practices for each of the segment identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
